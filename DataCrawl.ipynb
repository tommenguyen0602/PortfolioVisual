{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6ztmLQM9-QD",
        "outputId": "8feb4852-6609-4238-c892-d4dcbe52e812"
      },
      "outputs": [],
      "source": [
        "#!pip install beautifulsoup4 requests selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Collecting Signal IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydFaJMuI-sky"
      },
      "outputs": [],
      "source": [
        "# The base URL of the website we want to crawl\n",
        "base_url = 'https://www.mql5.com/en/signals/mt5/list/page'\n",
        "\n",
        "# The list of pages we want to crawl // Useless code \n",
        "page_urls = ['1']\n",
        "\n",
        "# The CSV file we want to write the data to\n",
        "csv_file = open('signal_list.csv', 'w', newline='')\n",
        "writer = csv.writer(csv_file)\n",
        "writer.writerow(['Signal Id'])\n",
        "\n",
        "# Loop over each page URL and extract the Signal ID data\n",
        "for page_url in page_urls:\n",
        "    # Construct the full URL for the page\n",
        "    url = base_url + page_url\n",
        "\n",
        "    # Make a GET request to the page\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Parse the HTML content of the page using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Find all the element has id \n",
        "    ids = soup.find_all('div', class_='button button_white-and-green')\n",
        "\n",
        "    #extrac the id\n",
        "    for id in ids:\n",
        "        name = id.get(\"data-id\")\n",
        "        # Write the data to the CSV file\n",
        "        writer.writerow([name])\n",
        "\n",
        "# Close the CSV file\n",
        "csv_file.close()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Viewing IDs List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of     Signal Id\n",
              "0     1368342\n",
              "1     1636506\n",
              "2      843451\n",
              "3     1486477\n",
              "4     1818780\n",
              "5     1598419\n",
              "6     1245170\n",
              "7     1722050\n",
              "8     1725375\n",
              "9     1334849\n",
              "10    1712504\n",
              "11    1857419\n",
              "12    1788678\n",
              "13    1766488\n",
              "14    1726461\n",
              "15    1829142\n",
              "16    1895985\n",
              "17     951062\n",
              "18    1778541\n",
              "19    1888377\n",
              "20    1405177\n",
              "21    1759554\n",
              "22    1694912\n",
              "23    1184516\n",
              "24    1855883\n",
              "25    1273204\n",
              "26    1894325\n",
              "27    1780040\n",
              "28    1531887\n",
              "29     910374\n",
              "30    1526229\n",
              "31    1312512\n",
              "32    1612455\n",
              "33    1274869\n",
              "34    1594934\n",
              "35    1908576\n",
              "36    1507561\n",
              "37    1607553\n",
              "38    1415131\n",
              "39    1882495\n",
              "40    1059619\n",
              "41    1196985\n",
              "42    1500355\n",
              "43    1722761\n",
              "44    1279728\n",
              "45    1729929\n",
              "46    1833703\n",
              "47    1815355>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "IDs = pd.read_csv(\"signal_list.csv\")\n",
        "IDs.head\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3rL9IaHTBZbP"
      },
      "outputs": [],
      "source": [
        "base_url_singleID = 'https://www.mql5.com/en/signals/'\n",
        "\n",
        "#load the csv containing Signal IDs\n",
        "with open('signal_details.csv', 'w', newline='') as signal_detailsFile:\n",
        "  writer = csv.writer(signal_detailsFile)\n",
        "  writer.writerow(['Signal Id','Trades','ProfitTrades','LossTrades','BestTrades','WorstTrades','GrossProfit','GrossLoss','SharpeRatio','RecoveryFactor','ProfitFactor','ExpectedPayoff'])\n",
        "  for row in IDs['Signal Id']:\n",
        "    url = base_url_singleID + str(row) + \"?source=Unknown#!tab=stats\"\n",
        "    \n",
        "    #Crawl each signal\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    values = soup.find_all('div', class_='s-data-columns__value')\n",
        "\n",
        "    # Loop over each product and extract the data\n",
        "    signalTrades = values[0].text \n",
        "\n",
        "\n",
        "    # Get total number of profit trades\n",
        "    s = values[1].text\n",
        "    number_regex = r\"([\\d\\s]+)\\s*\\(.*\\)\"\n",
        "    match = re.search(number_regex, s)\n",
        "    if match:\n",
        "        number = match.group(1)\n",
        "        # Remove spaces and normalize the number\n",
        "        normalized_number = float(number.replace(\" \", \"\").replace(\",\", \"\"))\n",
        "    signalProfitTrades = normalized_number\n",
        "\n",
        "    # Get total number of loss trades\n",
        "\n",
        "    s = values[2].text\n",
        "    number_regex = r\"([\\d\\s]+)\\s*\\(.*\\)\"\n",
        "    match = re.search(number_regex, s)\n",
        "    if match:\n",
        "        number = match.group(1)\n",
        "        # Remove spaces and normalize the number\n",
        "        normalized_number = float(number.replace(\" \", \"\").replace(\",\", \"\"))\n",
        "    signalLossTrades = normalized_number\n",
        "\n",
        "    signalBestTrade = values[3].find('i').text\n",
        "    signalWorstTrade = values[4].find('i').text\n",
        "\n",
        "    signalGrossProfit = values[5].find('i').text\n",
        "    signalGrossLoss = values[6].find('i').text\n",
        "\n",
        "    signalSharpeRatio = values[9].text\n",
        "\n",
        "    signalRecoveryFactor = values[15].text\n",
        "\n",
        "\n",
        "    signalProfitFactor = values[18].text\n",
        "\n",
        "    signalExpectedPayoff = values[19].find('i').text\n",
        "    writer.writerow([row,signalTrades,signalProfitTrades,signalLossTrades,signalBestTrade,signalWorstTrade,signalGrossProfit,signalGrossLoss,signalSharpeRatio,signalRecoveryFactor,signalProfitFactor,signalExpectedPayoff])\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TLyREx7CD5PH"
      },
      "source": [
        "View Signal Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signals = pd.read_csv(\"signal_details.csv\")\n",
        "signals"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
